version: '3.8'

services:
  # PostgreSQL with pgvector extension
  postgres:
    image: ankane/pgvector:latest
    container_name: smartpresence_db
    environment:
      POSTGRES_DB: smartpresence
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${DB_PASSWORD:-postgres}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/scripts/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - smartpresence_network

  # Redis (optional, for caching)
  redis:
    image: redis:7-alpine
    container_name: smartpresence_redis
    command: redis-server --appendonly yes
    # Bind Redis to a non-conflicting host port; keep internal 6379
    ports:
      - "6380:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - smartpresence_network

  # FastAPI Backend
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
      cache_from:
        - smartpresence_backend:latest
    image: smartpresence_backend:latest
    container_name: smartpresence_backend
    environment:
      DATABASE_URL: postgresql+psycopg://postgres:${DB_PASSWORD:-postgres}@postgres:5432/smartpresence
      REDIS_URL: redis://redis:6379/0
      SECRET_KEY: ${SECRET_KEY:-change-this-in-production}
      JWT_SECRET_KEY: ${JWT_SECRET_KEY:-change-this-jwt-secret}
      ALGORITHM: HS256
      ACCESS_TOKEN_EXPIRE_MINUTES: 30
      FACIAL_CONFIDENCE_THRESHOLD: 0.6
      CORS_ORIGINS: http://localhost:3000,http://localhost:8000
      UPLOAD_DIR: /app/uploads
      # AI Agent configuration
      GROQ_API_KEY: ${GROQ_API_KEY:-}
      GOOGLE_API_KEY: ${GOOGLE_API_KEY:-}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - /app/__pycache__
      - upload_data:/app/uploads
      - chroma_data:/app/chroma_db
    working_dir: /app
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: >
      sh -c "
        echo 'Starting FastAPI server...' &&
        uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
      "
    networks:
      - smartpresence_network

  # Next.js Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: dev
      cache_from:
        - smartpresence_frontend:latest
      args:
        NEXT_PUBLIC_API_BASE_URL: http://localhost:8000
    image: smartpresence_frontend:latest
    container_name: smartpresence_frontend
    environment:
      NEXT_PUBLIC_API_BASE_URL: http://localhost:8000
      NODE_ENV: development
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
      - /app/.next
    depends_on:
      - backend
    command: npm run dev
    networks:
      - smartpresence_network

  # Gotenberg - PDF Generation Service (for N8N Workflow 5)
  gotenberg:
    image: gotenberg/gotenberg:8
    container_name: gotenberg
    ports:
      - "3001:3000"  # Host:Container (avoiding conflict with frontend on 3000)
    environment:
      - GOTENBERG_API_TIMEOUT=30s
      - GOTENBERG_API_DISABLE_ROUTES=false
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - smartpresence_network
    restart: unless-stopped

  # NTIC2 AI Agent - Backend (FastAPI) + Frontend (Vite/Nginx)
  ntic2-postgres:
    image: postgres:15
    container_name: ntic2_postgres
    environment:
      POSTGRES_DB: ntic2
      POSTGRES_USER: ntic
      POSTGRES_PASSWORD: ntic
    ports:
      - "5434:5432"  # avoid conflict with main postgres
    volumes:
      - ntic2_pgdata:/var/lib/postgresql/data
      - ./ntic2_ai_agent_production/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - smartpresence_network

  ntic2-ollama:
    image: ollama/ollama:latest
    container_name: ntic2_ollama
    ports:
      - target: 11434
        published: ${NTIC2_OLLAMA_PORT:-11435}
        protocol: tcp
    volumes:
      - ntic2_ollama_data:/root/.ollama
    networks:
      - smartpresence_network

  ntic2-backend:
    build:
      context: ./ntic2_ai_agent_production/backend
      dockerfile: Dockerfile
    container_name: ntic2_backend
    env_file:
      - ./ntic2_ai_agent_production/.env
    environment:
      LLM_PROVIDER: ${LLM_PROVIDER:-groq}
      OLLAMA_BASE_URL: http://ntic2-ollama:11434
      GROQ_API_KEY: ${GROQ_API_KEY:-}
      HF_API_KEY: ${HF_API_KEY:-}
    depends_on:
      - ntic2-postgres
      - ntic2-ollama
    volumes:
      - ./ntic2_ai_agent_production/backend:/app
      - ntic2_chroma_data:/app/chroma_db
    ports:
      - "5000:5000"
    networks:
      - smartpresence_network

  ntic2-frontend:
    build:
      context: ./ntic2_ai_agent_production/frontend
      dockerfile: Dockerfile
    container_name: ntic2_frontend
    depends_on:
      - ntic2-backend
    ports:
      - "8080:80"
    networks:
      - smartpresence_network

networks:
  smartpresence_network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  upload_data:
  chroma_data:
  ntic2_pgdata:
  ntic2_ollama_data:
  ntic2_chroma_data:
